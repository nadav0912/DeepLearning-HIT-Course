{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d0d0f3a",
   "metadata": {},
   "source": [
    "### 5. Comparison and Conclusions\n",
    "\n",
    "#### Comparison with Custom CNN\n",
    "Comparing this Transfer Learning experiment to my custom CNN from the previous exercise revealed a significant trade-off between model complexity and efficiency. My custom CNN was lightweight and designed specifically for $28 \\times 28$ inputs, allowing it to complete training very quickly. In contrast, the ResNet-18 model is a much heavier architecture with millions of parameters. Even though I reduced the training duration to just **7 epochs**, the **total training time was longer** than my custom model. This is because each individual step required significantly more computation, further increased by the overhead of resizing images to $64 \\times 64$. While the pre-trained weights allowed the model to reach high accuracy in fewer epochs, the \"wall-clock\" time to get there was higher, proving that for simple datasets like FashionMNIST, a massive pre-trained model can be computationally inefficient compared to a smaller, custom-built solution.\n",
    "\n",
    "#### The Tuning Process & Unfreezing Layers\n",
    "Getting the ResNet model to perform well required significant iteration with hyperparameters. Initially, I treated the ResNet strictly as a fixed feature extractor, freezing all layers and using a standard learning rate. However, the model struggled to converge smoothly. The turning point came when I switched to the **Adam optimizer** and significantly **lowered the starting learning rate to 0.0001**. This smaller step size allowed the model to fine-tune the weights without destroying the pre-learned features. Additionally, **unfreezing Layer 4** (the final convolutional block) was crucial. It became clear that the original weights in the deeper layers were too specialized for ImageNet objects; by unfreezing them, I allowed the model to repurpose those high-level filters to recognize clothing-specific features like sleeves and zippers, which immediately broke the performance plateau.\n",
    "\n",
    "#### The Challenge of Domain Mismatch\n",
    "One key finding from this assignment is that Transfer Learning is not a \"magic bullet\" when the source and target domains are vastly different. ResNet was trained on ImageNetâ€”high-resolution, colorful, real-world photography. FashionMNIST, on the other hand, consists of tiny, grayscale, low-contrast icons. This \"domain gap\" explains why the model didn't immediately achieve near-perfect results. Unlike a scenario where we transfer from \"photos of cats\" to \"photos of dogs,\" here we transferred from \"photos of the world\" to \"pixelated icons of clothes.\" This mismatch made the data preprocessing (duplicating channels, resizing to 64x64) and the fine-tuning of deeper layers absolutely critical to the model's success."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
